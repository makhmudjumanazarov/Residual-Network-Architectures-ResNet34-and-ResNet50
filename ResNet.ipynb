{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building  Residual Networks\n",
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity\n",
    "from tensorflow.keras import Model, Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Identity Block\n",
    "\n",
    "The identity block is the standard block used in ResNets, and corresponds to the case where the input activation (say $a^{[l]}$) has the same dimension as the output activation (say $a^{[l+2]}$). To flesh out the different steps of what happens in a ResNet's identity block, here is an alternative diagram showing the individual steps:\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"https://github.com/makhmudjumanazarov/Residual-Network-Architectures-ResNet34-and-ResNet50-/raw/main/Images/idblock_kiank.png\" style=\"width:650px;height:150px;\" />\n",
    "    <br>\n",
    "    <caption><center> <u> <font color='purple'> <b>Figure 1</b> </u><font color='purple'>  : <b>Identity block.</b> Skip connection \"skips over\" 2 layers. </center></caption>\n",
    "</div>\n",
    "\n",
    "The upper path is the \"shortcut path.\" The lower path is the \"main path.\" \n",
    "\n",
    "You'll actually implement a slightly more powerful version of this identity block, in which the skip connection \"skips over\" 3 hidden layers rather than 2 layers. It looks like this:\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"https://github.com/makhmudjumanazarov/Residual-Network-Architectures-ResNet34-and-ResNet50-/raw/main/Images/idblock3_kiank.png\" style=\"width:650px;height:150px;\" />\n",
    "    <br>\n",
    "    <caption><center> <u> <font color='purple'> <b>Figure 2</b> </u><font color='purple'>  : <b>Identity block.</b> Skip connection \"skips over\" 3 layers. </center></caption>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, training=True, initializer=random_uniform):\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value. You'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    ## Second component of main path (≈3 lines)\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training) \n",
    "    X = Activation('relu')(X) \n",
    "\n",
    "    ## Third component of main path (≈2 lines)\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training) \n",
    "    \n",
    "    ## Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X) \n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Convolutional Block\n",
    "\n",
    "The ResNet \"convolutional block\" is the second block type. You can use this type of block when the input and output dimensions don't match up. The difference with the identity block is that there is a CONV2D layer in the shortcut path: \n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"https://github.com/makhmudjumanazarov/Residual-Network-Architectures-ResNet34-and-ResNet50-/raw/main/Images/convblock_kiank.png\" style=\"width:650px;height:150px;\" />\n",
    "    <br>\n",
    "    <caption><center> <u> <font color='purple'> <b>Figure 3</b> </u><font color='purple'>  : <b>Convolutional block.</b> </center></caption>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, s = 2, training=True, initializer=glorot_uniform):\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "    # First component of main path glorot_uniform(seed=0)\n",
    "    X = Conv2D(filters = F1, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    ## Second component of main path\n",
    "    X = Conv2D(F2, (f, f), strides = (1,1), padding='same', kernel_initializer = initializer(seed=0))(X) \n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    X = Activation('relu')(X) \n",
    "\n",
    "    ## Third component of main path\n",
    "    X = Conv2D(F3, (1, 1), strides = (1,1), padding='valid', kernel_initializer = initializer(seed=0))(X) \n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    \n",
    "    ##### SHORTCUT PATH ##### \n",
    "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), padding='valid', kernel_initializer = initializer(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3)(X_shortcut, training=training)\n",
    "    \n",
    "    # Final step: Add shortcut value to main path (Use this order [X, X_shortcut]), and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Your ResNet Model (50 layers)\n",
    "\n",
    "You now have the necessary blocks to build a very deep ResNet. The following figure describes in detail the architecture of this neural network. \"ID BLOCK\" in the diagram stands for \"Identity block,\" and \"ID BLOCK x3\" means you should stack 3 identity blocks together.\n",
    "\n",
    "<img src=\"images/resnet_kiank.png\" style=\"width:850px;height:150px;\">\n",
    "<caption><center> <u> <font color='purple'> <b>Figure 4</b> </u><font color='purple'>  : <b>ResNet-50 model</b> </center></caption>\n",
    "\n",
    "The details of this ResNet-50 model are:\n",
    "- Zero-padding pads the input with a pad of (3,3)\n",
    "- Stage 1:\n",
    "    - The 2D Convolution has 64 filters of shape (7,7) and uses a stride of (2,2). \n",
    "    - BatchNorm is applied to the 'channels' axis of the input.\n",
    "    - MaxPooling uses a (3,3) window and a (2,2) stride.\n",
    "- Stage 2:\n",
    "    - The convolutional block uses three sets of filters of size [64,64,256], \"f\" is 3, and \"s\" is 1.\n",
    "    - The 2 identity blocks use three sets of filters of size [64,64,256], and \"f\" is 3.\n",
    "- Stage 3:\n",
    "    - The convolutional block uses three sets of filters of size [128,128,512], \"f\" is 3 and \"s\" is 2.\n",
    "    - The 3 identity blocks use three sets of filters of size [128,128,512] and \"f\" is 3.\n",
    "- Stage 4:\n",
    "    - The convolutional block uses three sets of filters of size [256, 256, 1024], \"f\" is 3 and \"s\" is 2.\n",
    "    - The 5 identity blocks use three sets of filters of size [256, 256, 1024] and \"f\" is 3.\n",
    "- Stage 5:\n",
    "    - The convolutional block uses three sets of filters of size [512, 512, 2048], \"f\" is 3 and \"s\" is 2.\n",
    "    - The 2 identity blocks use three sets of filters of size [512, 512, 2048] and \"f\" is 3.\n",
    "- The 2D Average Pooling uses a window of shape (2,2).\n",
    "- The 'flatten' layer doesn't have any hyperparameters.\n",
    "- The Fully Connected (Dense) layer reduces its input to the number of classes using a softmax activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape, classes):\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    \n",
    "    ## Stage 3 \n",
    "    X = convolutional_block(X, f=3, filters=[128, 128, 512], s=2) \n",
    "    X = identity_block(X, 3, [128, 128, 512]) \n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    \n",
    "    ## Stage 4\n",
    "    X = convolutional_block(X, f=3, filters=[256, 256, 1024],s=2) \n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "\n",
    "    ## Stage 5\n",
    "    X = convolutional_block(X, f=3, filters=[512, 512, 2048],s=2) \n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "\n",
    "    ## AVGPOOL. Use \"X = AveragePooling2D(...)(X)\"\n",
    "    X = AveragePooling2D(pool_size=(2, 2), padding='same')(X) \n",
    "    \n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(input_shape=(64, 64, 3), classes=6)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import ResNet50 from Tensorflow Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = tf.keras.applications.resnet50.ResNet50(\n",
    "    include_top=False,\n",
    "    input_shape= (64, 64, 3),\n",
    "    weights='imagenet'\n",
    ")\n",
    "resnet50.summary()\n",
    "model_res_50 = Sequential()\n",
    "for layer in resnet50.layers:\n",
    "    layer.trainable = False\n",
    "model_res_50.add(resnet50)\n",
    "model_res_50.add(Flatten())\n",
    "model_res_50.add(Dense(activation = \"relu\", units = 6))\n",
    "# model_res_50.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *👆👆👆 Compare ResNet50 Architecture from scratch and Import ResNet50 from Tensorflow Applications*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Your ResNet Model (34 layers)\n",
    "\n",
    "You now have the necessary blocks to build a very deep ResNet. The following figure describes in detail the architecture of this neural network.\n",
    "\n",
    "<img src=\"images/ResNet34.png\" style=\"width:850px;height:150px;\">\n",
    "<caption><center> <u> <font color='purple'> <b>Figure 5</b> </u><font color='purple'>  : <b>ResNet-34 model</b> </center></caption>\n",
    "\n",
    "The details of this ResNet-34 model are:\n",
    "- Zero-padding pads the input with a pad of (3,3)\n",
    "- Stage 1:\n",
    "    - The 2D Convolution has 64 filters of shape (7,7) and uses a stride of (2,2). \n",
    "    - BatchNorm is applied to the 'channels' axis of the input.\n",
    "    - MaxPooling uses a (3,3) window and a (2,2) stride.\n",
    "- Stage 2:\n",
    "    - The 3 Res_blocks use two sets of filters of size [64,64], \"f\" is 3 and strides = (1, 1).\n",
    "- Stage 3:\n",
    "    - The Res_block use two sets of filters of size [128,128], \"f\" is 3 and strides = (2, 2).\n",
    "    - The 3 Res_blocks use two sets of filters of size [128,128], \"f\" is 3 and strides = (1, 1).\n",
    "- Stage 4:\n",
    "    - The Res_block use two sets of filters of size [256,256], \"f\" is 3 and strides = (2, 2).\n",
    "    - The 5 Res_blocks use two sets of filters of size [256,256], \"f\" is 3 and strides = (1, 1).\n",
    "- Stage 5:\n",
    "    - The Res_block use two sets of filters of size [512,512], \"f\" is 3 and strides = (2, 2).\n",
    "    - The 2 Res_blocks use two sets of filters of size [512,512], \"f\" is 3 and strides = (1, 1).\n",
    "- The 2D Average Pooling uses a window of shape (2,2).\n",
    "- The 'flatten' layer doesn't have any hyperparameters.\n",
    "- The Fully Connected (Dense) layer reduces its input to the number of classes using a softmax activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Res_block(X, f, filters, s, training=True, initializer=glorot_uniform):\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "    # First component of main path glorot_uniform(seed=0)\n",
    "    X = Conv2D(filters=F1, kernel_size=(f, f), strides=(s, s), padding='same', kernel_initializer=initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X, training=training)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component of main path \n",
    "    X = Conv2D(F2, (f, f), strides=(1, 1), padding='same', kernel_initializer=initializer(seed=0))(X) \n",
    "    X = BatchNormalization(axis=3)(X, training=training)\n",
    "    \n",
    "    if s == 2:\n",
    "        X_shortcut = Conv2D(F2, (1, 1), strides=(s, s), kernel_initializer=initializer(seed=0))(X_shortcut)\n",
    "        X_shortcut = BatchNormalization(axis=3)(X_shortcut, training=training)\n",
    "\n",
    "    # Final step: Add shortcut value to main path (Use this order [X, X_shortcut]), and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet34(input_shape, classes):\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = Res_block(X, f = 3, filters=[64, 64], s = 1)\n",
    "    X = Res_block(X, f = 3, filters=[64, 64], s = 1)\n",
    "    X = Res_block(X, f = 3, filters=[64, 64], s = 1)\n",
    "    \n",
    "    ## Stage 3\n",
    "    X = Res_block(X, f = 3, filters=[128, 128], s = 2)\n",
    "    X = Res_block(X, f = 3, filters=[128, 128], s = 1)\n",
    "    X = Res_block(X, f = 3, filters=[128, 128], s = 1)\n",
    "    X = Res_block(X, f = 3, filters=[128, 128], s = 1)\n",
    "    \n",
    "    ## Stage 4\n",
    "    X = Res_block(X, f = 3, filters=[256, 256], s = 2)\n",
    "    X = Res_block(X, f = 3, filters=[256, 256], s = 1)\n",
    "    X = Res_block(X, f = 3, filters=[256, 256], s = 1)\n",
    "    X = Res_block(X, f = 3, filters=[256, 256], s = 1)\n",
    "    X = Res_block(X, f = 3, filters=[256, 256], s = 1)\n",
    "    X = Res_block(X, f = 3, filters=[256, 256], s = 1)\n",
    "\n",
    "    ## Stage 5\n",
    "    X = Res_block(X, f = 3, filters=[512, 512], s = 2)\n",
    "    X = Res_block(X, f = 3, filters=[512, 512], s = 1)\n",
    "    X = Res_block(X, f = 3, filters=[512, 512], s = 1)\n",
    "\n",
    "    ## AVGPOOL. Use \"X = AveragePooling2D(...)(X)\"\n",
    "    X = AveragePooling2D(pool_size=(2, 2), padding='same')(X) \n",
    "    \n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet34(input_shape=(64, 64, 3), classes=10)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
